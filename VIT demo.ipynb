{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "id": "B88741F6D9CA4696971FA6C9FCF243E8",
    "jupyter": {},
    "mdEditEnable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 0ã€å‰è¨€\n",
    "\n",
    "![Image Name](https://img2.baidu.com/it/u=1905334638,2514843252&fm=26&fmt=auto&gp=0.jpg)\n",
    "åœ¨é¥è¿œçš„21ä¸–çºªåˆï¼Œä¼´éšç€è®¡ç®—æœºç¡¬ä»¶çš„å‘å±•å’Œ~~äººæ°‘ç”Ÿæ´»æ°´å¹³çš„æé«˜~~\n",
    "hintonç­‰äººæå‡ºçš„æ·±åº¦ç¥ç»ç½‘ç»œï¼Œæœºå™¨å­¦ä¹ ï¼Œè‡ªç„¶è¯­è¨€å¤„ç†ä»¥åŠè®¡ç®—æœºè§†è§‰ç­‰é¢†åŸŸéƒ½è·å¾—äº†é•¿è¶³çš„å‘å±•ã€‚\n",
    "ä¼´éšç€æ—¶é—´çš„è¿›ç¨‹\n",
    "å½“åˆå± é¾™çš„å°‘å¹´ï¼ŒCNNä¸çŸ¥ä¸è§‰ä¹Ÿå·²ç»æˆé•¿ä¸ºæœºå™¨å­¦ä¹ æ—¶ä»£çš„å·¨é¾™ã€‚\n",
    "è¿‘å¹´æ¥ï¼ŒCNNçš„å‘å±•è¿›å…¥äº†ç“¶é¢ˆæœŸï¼Œé•¿æœŸå¯¹äºå·ç§¯ç¥ç»ç½‘ç»œçš„ä¾èµ–é™åˆ¶äº†è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•ã€‚\n",
    "äºæ˜¯ï¼Œåˆå‡ºç°äº†å± é¾™çš„å°‘å¹´ï¼Œæ¥è‡ªäºå¼‚æ¬¡å…ƒNLP\n",
    "ä¸¾èµ·transformerçš„å®åˆ€ï¼Œä¸€å¾€æ— å‰ï¼\n",
    "\n",
    "çŠŠå­æ‰¯å®Œï¼Œä¸‹é¢è¯´æ­£äº‹ï¼Œè¿™æ˜¯æ–°å¼€çš„å¯¹äºtransformeræœ€æ–°çš„è®ºæ–‡è®²è§£ä»¥åŠdemoå®éªŒçš„ç³»åˆ—ã€‚\n",
    "ä½œä¸ºè¯¥ç³»åˆ—çš„ç¬¬ä¸€ç¯‡ï¼Œæœ¬æ–‡æƒ³è¦å‘å¤§å®¶ä»‹ç»è§†è§‰transformeré¢†åŸŸæœ€å¸¸è§çš„æ–¹æ¡ˆVision Transformerï¼ˆVITï¼‰\n",
    "ä»¥åŠä¸€äº›åŸºç¡€çŸ¥è¯†ã€‚ä»…åšåˆ†äº«ï¼Œæ¬¢è¿è®¨è®ºã€‚\n",
    "\n",
    "ä½œè€…ï¼šä¸è´° æ¨¡å¼è¯†åˆ«åšå£«åœ¨è¯»\n",
    "ç‰ˆæƒå£°æ˜ï¼šæ­¤æ–‡çš„æ‰€æœ‰æ–‡å­—ã€å›¾ç‰‡ã€ä»£ç ä»¥åŠç›¸åº”æ•°æ®æ–‡ä»¶çš„ç‰ˆæƒå½’æœ¬äºº(å’Œé²¸ç¤¾åŒºæ˜µç§°ï¼šä¸è´°)æ‰€æœ‰ï¼Œæ–‡è´£è‡ªè´Ÿã€‚ä¸¥ç¦ä»»ä½•å•†ä¸šæ€§è´¨çš„è½¬è½½ã€‚å…¬ç›Šæ€§è´¨è½¬è½½éœ€è”ç³»ä½œè€…æœ¬äººè·å–æˆæƒã€‚è½¬è½½æœ¬æ–‡æ—¶ï¼Œè¯·åŠ¡å¿…æ–‡å­—æ³¨æ˜â€œæ¥è‡ªï¼šï¼ˆå’Œé²¸ç¤¾åŒºï¼šä¸è´°ï¼‰â€ï¼Œå¹¶é™„å¸¦æœ¬é¡¹ç›®[è¶…é“¾æ¥](https://www.heywhale.com/mw/project/60d980b694c44a0017dc0c5f?token=8ee278ebaa063c30)ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "604190BC98854C79A9A257E726CA155E",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 1ã€Motivation\n",
    "## 1.1ã€Drawbacks in CNN\n",
    "åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸï¼Œè§†è§‰ä¿¡æ¯é€šå¸¸å¯ä»¥è¢«çœ‹ä¸ºæ˜¯åƒç´ ç»„æˆçš„æ•°ç»„ã€‚è¿™äº›æ•°ç»„é€šè¿‡å·ç§¯æ“ä½œè¿›è¡Œåº•å±‚ç‰¹å¾æå–ï¼Œè¯­ä¹‰ä¿¡æ¯åˆ†æå¹¶å®Œæˆè§„å®šçš„ä»»åŠ¡æ¯”å¦‚å›¾ç‰‡åˆ†ç±»ï¼Œç›®æ ‡è¯†åˆ«ç­‰ç­‰ã€‚\n",
    "å°½ç®¡åŸºäºCNNçš„å„ç§ç½‘ç»œå·²ç»åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸå–å¾—äº†å·¨å¤§çš„è¿›å±•ï¼Œä»ç„¶æœ‰è®¸å¤šé—®é¢˜æ˜¯éœ€è¦è¢«è§£å†³çš„ã€‚\n",
    "### 1.1.1ã€å…³äºåƒç´ çš„å·®å¼‚æ€§\n",
    "ä¸åŒçš„ä»»åŠ¡é€šç•…å¯¹äºå›¾ç‰‡çš„åƒç´ ä¼šæœ‰ä¸åŒçš„è¦æ±‚ï¼šåœ¨åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬åº”å½“æ›´å¤šçš„å…³æ³¨äºå‰æ™¯ç›®æ ‡è€Œå¿½ç•¥èƒŒæ™¯ç›®æ ‡ï¼Œåœ¨åˆ†å‰²ä»»åŠ¡ä¸­ï¼Œæ¨¡å‹åº”è¯¥æ›´å¤šçš„è€ƒè™‘è¡Œäººï¼Œè€Œä¸æ˜¯è¿æˆç‰‡çš„å¤©ç©ºï¼Œé“è·¯ï¼Œè‰åœ°ç­‰ç­‰ã€‚ç„¶è€Œï¼Œå·ç§¯ç½‘ç»œå´æ²¡æœ‰åŠæ³•å®ç°è¿™ä¸ªåŠŸèƒ½ï¼Œä»–å¯¹äºæ‰€æœ‰å›¾åƒå—/åƒç´ ç‚¹å‡åŒ€çš„è¿›è¡Œå¤„ç†è€Œä¸è€ƒè™‘ä»–ä»¬çš„é‡è¦æ€§å·®å¼‚ã€‚è¿™ä¸ªç¼ºé™·ä¼šå¯¼è‡´æ¨¡å‹åœ¨ç©ºé—´ç‰¹å¾çš„æŒ–æ˜ä¸Šæ¯”è¾ƒä½æ•ˆï¼Œä»è€Œå¯¼è‡´æ¯”è¾ƒé«˜çš„è®¡ç®—åŠ›ä»¥åŠæ¯”è¾ƒå·®çš„ç‰¹å¾è¡¨è¾¾èƒ½åŠ›ã€‚\n",
    "### 1.1.2ã€å…³äºå›¾åƒçš„ä¸ªæ€§åŒ–\n",
    "åœ¨ä½¿ç”¨å·ç§¯ç¥ç»æå–å›¾åƒç‰¹å¾çš„æ—¶å€™ï¼Œå¯ä»¥åˆ†ä¸ºä½çº§å½¢çŠ¶ç‰¹å¾çš„æå–ä»¥åŠé«˜çº§è¯­ä¹‰ä¿¡æ¯çš„æå–ã€‚è¿™å°±å¯¼è‡´äº†ä¸€ä¸ªæˆ‘ä»¬éœ€è¦æ³¨æ„çš„é—®é¢˜ï¼Œå¹¶ä¸æ˜¯æ‰€æœ‰çš„å›¾ç‰‡éƒ½ä¼šåŒ…å«ç½‘ç»œå­¦ä¹ åˆ°çš„æ‰€æœ‰é«˜çº§è¯­ä¹‰ç‰¹å¾ã€‚ä½çº§çš„è¯­ä¹‰ç‰¹å¾æ¯”å¦‚è§’è½å’Œè¾¹ä¼šåœ¨æ‰€æœ‰çš„è‡ªç„¶å›¾ç‰‡ä¸­è‡ªç„¶çš„å­˜åœ¨ï¼Œæ‰€ä»¥å¯¹äºæ‰€æœ‰çš„å›¾ç‰‡ä½¿ç”¨ä¸€æ ·çš„å·ç§¯æ ¸æ¥æå–ä½çº§è¯­ä¹‰ç‰¹å¾æ˜¯OKçš„ã€‚ä½†æ˜¯ä¸€äº›é«˜çº§çš„è¯­ä¹‰ç‰¹å¾ï¼Œæ¯”å¦‚è€³æœµçš„å½¢çŠ¶ï¼Œç‹—ç‹—çš„å½¢çŠ¶ï¼Œè¿™äº›é«˜çº§ç‰¹å¾åªä¼šå‡ºç°åœ¨ç‰¹å®šçš„å›¾ç‰‡ä¸­è€Œä¸æ˜¯æ‰€æœ‰çš„å›¾ç‰‡ï¼Œæ‰€ä»¥ä½¿ç”¨æ‰€æœ‰çš„é«˜çº§è¯­ä¹‰ç‰¹å¾æå–çš„å·ç§¯æ ¸å»å¯¹å›¾ç‰‡è¿›è¡Œå¤„ç†æ˜¯é«˜æ¶ˆè€—è€Œä¸”ä¸ç»æµçš„ã€‚æ¯”å¦‚ç‹—çš„ä¸€äº›ç‰¹å¾æ˜¯ä¸ä¼šå‡ºç°åœ¨åªåŒ…å«èŠ±ï¼Œè‰ï¼Œè½¦è¾†çš„å›¾ç‰‡å½“ä¸­çš„ï¼Œç°æœ‰å·ç§¯ç½‘ç»œçš„è¿™ç§ç‰¹æ€§ä¼šå¯¼è‡´å¤§é‡çš„ç½•è§å·ç§¯æ ¸è¢«è®­ç»ƒå‡ºæ¥ï¼Œå¹¶ä¸”å¤§å¹…åº¦å¢åŠ ç½‘ç»œçš„å¼€é”€ã€‚\n",
    "### 1.1.3ã€å…³äºç»“æ„\n",
    "æ¯ä¸ªå·ç§¯æ ¸éƒ½ä¼šå¯¹ä¸€å°ç‰‡åŒºåŸŸè¿›è¡Œå¤„ç†ï¼Œä½†æ˜¯å¯¹äºè¯­ä¹‰ä¿¡æ¯æ¥è¯´é•¿ä¾èµ–å…³ç³»æ˜¯ååˆ†é‡è¦çš„ã€‚ä¸ºäº†å¢åŠ è¿™ç§é•¿ä¾èµ–å…³ç³»ï¼Œæˆ–è€…è¯´ç©ºé—´-è·ç¦»ä¸Šçš„ä¾èµ–å…³ç³»ï¼Œä¹‹å‰çš„æ–¹æ³•å°è¯•å¢å¤§å·ç§¯æ ¸çš„å¤§å°ï¼Œå¢åŠ æ¨¡å‹çš„æ·±åº¦ï¼Œé‡‡ç”¨æ–°çš„å·ç§¯æ–¹æ³•æ¯”å¦‚ç©ºæ´å·ç§¯ç­‰ç­‰ã€‚è¿™äº›æ“ä½œçš„æœ¬è´¨éƒ½æ˜¯å¸Œæœ›å¢å¤§æ„Ÿå—é‡çš„é¢ç§¯ï¼Œä»è€Œæé«˜æ¨¡å‹å¯¹äºå…¨å±€ä¿¡æ¯çš„å…³æ³¨èƒ½åŠ›ã€‚ä½†æ˜¯ä¸Šè¿°æ–¹æ³•åœ¨æŸç§ç¨‹åº¦ä¸Šéƒ½å¢åŠ äº†æ¨¡å‹çš„å¤æ‚åº¦å’Œè®¡ç®—å¼€é”€ã€‚\n",
    "\n",
    "![Image Name](https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fwww.pianshen.com%2Fimages%2F106%2Fa003bc575357859c67cb48634292a622.png&refer=http%3A%2F%2Fwww.pianshen.com&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=jpeg?sec=1627472456&t=426386fb00142112465d0cc02a4003a5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true,
    "id": "CC2DD3299E33486B8E928AED398A489C",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "60d980ca94c44a0017dc0c61",
    "slideshow": {
     "slide_type": "slide"
    },
    "solution": "hidden",
    "solution_first": true,
    "tags": []
   },
   "source": [
    "## 1.2ã€Why ViT?\n",
    "ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½œè€…ç›´æ¥é¢å‘æœ¬è´¨åŸå› åŸºäºåƒç´ çš„å·ç§¯æœºåˆ¶ï¼Œæå‡ºäº†åŸºäºè§†è§‰çš„Transformerï¼švision transformerã€‚é‚£ä¹ˆä¸ºä»€ä¹ˆè¦æå‡ºVision Transformerå‘¢ï¼Ÿæˆ‘ä»¬å°è¯•ä»è‡ªæ³¨æ„åŠ›æœºåˆ¶å’ŒNLPä¸­çš„transformerè¿™ä¸¤ä¸ªè§’åº¦æ¥å›ç­”è¿™ä¸ªé—®é¢˜ã€‚å¹¶ä¸”åœ¨1.2.3å°èŠ‚ä¸­å‘å¤§å®¶ä»‹ç»vitçš„ä¸»è¦å†…å®¹ã€‚\n",
    "### 1.2.1ã€è‡ªæ³¨æ„åŠ›æœºåˆ¶\n",
    "è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆself attentionï¼‰æ˜¯æ³¨æ„åŠ›æœºåˆ¶ä¸­çš„ä¸€ç§ï¼Œä¹Ÿæ˜¯transformerä¸­çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚è¦æƒ³äº†è§£ä»€ä¹ˆæ˜¯è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œé¦–å…ˆè¦ç»™å¤§å®¶ä»‹ç»ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æœºåˆ¶ã€‚\n",
    "#### 1.2.1.1 æ³¨æ„åŠ›æœºåˆ¶\n",
    "æ³¨æ„åŠ›æœºåˆ¶çš„ç›®çš„æ˜¯æ ¹æ®ç‰¹å®šçš„ç›®æ ‡ï¼Œå»å…³æ³¨å„ä¸ªregionå’Œç‰¹å®šç›®æ ‡çš„å…³è”ç¨‹åº¦ã€‚é‚£ä¹ˆè¦å®Œæˆè¿™ä¸ªä»»åŠ¡ï¼Œæˆ‘ä»¬é¦–å…ˆå°±è¦ç¡®å®šå¦‚ä½•å»è®¡ç®—è¿™ä¸ªå…³è”ç¨‹åº¦ã€‚\n",
    "æ‹¿ä¸¤ä¸ªå¥å­æ¥ä¸¾ä¾‹çš„è¯ï¼š\n",
    "![Image Name](https://cdn.kesci.com/upload/image/qveu8hjzb0.png?imageView2/0/w/960/h/960)\n",
    "è¦æƒ³çŸ¥é“è¿™ä¸¤å¥è¯è¡¨è¾¾çš„æ˜¯ä¸æ˜¯åŒä¸€ä¸ªæ„æ€ï¼Œæˆ‘ä»¬é¦–å…ˆè¦æŠŠæ¯ä¸ªå•è¯å»åšword embeddingï¼ŒæŠ½è±¡æˆç½‘ç»œå¯ä»¥è¯†åˆ«çš„å‘é‡ã€‚ç„¶åè®¡ç®—ä¸¤ä¸ªå¥å­ä¹‹é—´è¯ä¸è¯çš„ç›¸ä¼¼åº¦ï¼Œå½’ä¸€åŒ–åä½œä¸ºæƒé‡ï¼Œå¹¶é€šè¿‡æƒé‡ä»¥åŠå¦ä¸€ä¸ªå¥å­çš„å„ä¸ªè¯å‘é‡ï¼Œç»“åˆèµ·æ¥å¾—åˆ°ç”¨å¦ä¸€ä¸ªå¥å­è¡¨ç¤ºçš„è¯¥è¯çš„è¯å‘é‡ã€‚\n",
    "\n",
    "å‡è®¾æˆ‘ä»¬å¯¹Iåˆ†æï¼Œæˆ‘ä»¬çš„queryæ˜¯Iï¼Œæˆ‘ä»¬è®¡ç®—Iæ‰€å¯¹åº”çš„è¯å‘é‡å’Œyouï¼Œandï¼Œmeè¿™å‡ ä¸ªè¯å‘é‡ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œç„¶åå¯¹ç›¸ä¼¼åº¦å½’ä¸€åŒ–å¾—åˆ°æƒé‡å†å»å’Œyouï¼Œandï¼Œmeå‡ ä¸ªè¯è¯­ç›¸ä¹˜ã€‚è¿™ä¹ˆæ“ä½œæˆ‘ä»¬å°±å¾—åˆ°äº†ç¬¬äºŒå¥è¯æ ¹æ®Iæ„å»ºçš„è¯å‘é‡ï¼Œç„¶åä¸æ–­ç”¨ç¬¬äºŒå¥è¯å»è¡¨ç¤ºç¬¬ä¸€å¥è¯çš„æ¯ä¸ªè¯ï¼Œç„¶åå¯¹æ¯”æ–°å¥å­å’ŒåŸå¥å­ä¹‹é—´çš„å·®å¼‚ç¨‹åº¦ï¼Œå°±å¯ä»¥ç”¨æ¥åˆ¤æ–­è¿™ä¸¤ä¸ªæ©˜å­è¡¨è¾¾çš„æ˜¯ä¸æ˜¯åŒä¸€ä¸ªæ„æ€ã€‚\n",
    "\n",
    "#### 1.2.1.2 è‡ªæ³¨æ„åŠ›æœºåˆ¶\n",
    "ä¸Šé¢æ‰€åˆ—ä¸¾çš„ä¾‹å­ï¼Œä¸¤å¥è¯è¡¨è¾¾çš„æ„æ€ä¸ä¸€æ ·ï¼Œå‡è®¾è¿™ä¸¤å¥è¯æ˜¯åŒä¸€å¥è¯ï¼Œé‚£ä¹ˆè®¡ç®—è¿™ä¸ªæƒé‡çš„è¿‡ç¨‹å°±å¯ä»¥çœ‹ä¸ºç”¨è‡ªå·±è¡¨è¾¾è‡ªå·±ï¼Œä¹Ÿå°±æ˜¯åœ¨è®¡ç®—è‡ªå·±çš„æ¯ä¸ªlcoalä¹‹é—´çš„å…³è”åº¦ã€‚æˆ‘ä»¬æŠŠè¿™ä¸ªè¿‡ç¨‹ç§°ä¸ºself attentionã€‚è¿™ä¹ˆåšå¯ä»¥å……åˆ†è€ƒè™‘ä¸åŒçš„è¯å‘é‡ä¹‹é—´çš„å…³è”åº¦ï¼Œè§£å†³äº†ä¹‹å‰æåˆ°çš„ç”±äºå·ç§¯å¸¦æ¥çš„çŸ­ä¾èµ–å…³ç³»ã€‚\n",
    "\n",
    "ä¸ºäº†æ›´å¥½çš„å»è®¡ç®—è¿™ä¸ªè‡ªæ³¨æ„åŠ›çš„è¿‡ç¨‹ï¼Œæˆ‘ä»¬å¯¹äºæ¯ä¸ªè¯å‘é‡éƒ½ä¼šæŠ½è±¡åˆqueryï¼ˆQï¼‰ï¼Œkey(K)ï¼Œvalue(V)è¿™ä¸‰ä¸ªå€¼æ¥ï¼Œç„¶åæ ¹æ®ä¸‹é¢çš„å…¬ç¤ºå»è®¡\n",
    "![Image Name](https://cdn.kesci.com/upload/image/qveusecwbw.png?imageView2/0/w/640/h/640)\n",
    "ç»™å®šTargetä¸­çš„æŸä¸ªå…ƒç´ Queryï¼Œé€šè¿‡è®¡ç®—Queryå’Œå„ä¸ªKeyçš„ç›¸ä¼¼æ€§æˆ–è€…ç›¸å…³æ€§ï¼Œå¾—åˆ°æ¯ä¸ªKeyå¯¹åº”Valueçš„æƒé‡ç³»æ•°ï¼Œç„¶åå¯¹Valueè¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œå³å¾—åˆ°äº†æœ€ç»ˆçš„Attentionæ•°å€¼ã€‚æ‰€ä»¥æœ¬è´¨ä¸ŠAttentionæœºåˆ¶æ˜¯å¯¹Sourceä¸­å…ƒç´ çš„Valueå€¼è¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œè€ŒQueryå’ŒKeyç”¨æ¥è®¡ç®—å¯¹åº”Valueçš„æƒé‡ç³»æ•°ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6F2924EE56F0433587ADD1A8A7305310",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "60d980ca94c44a0017dc0c61",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 1.2.2ã€Transformer in NLP\n",
    "Transformeråœ¨NLPä¸­çš„å¤§èŒƒå›´åº”ç”¨å¯ä»¥è¯´èµ·æºäºAttention is all you needè¿™ç¯‡è®ºæ–‡ã€‚\n",
    "ä¼—æ‰€å‘¨çŸ¥ï¼Œè¿™ç¯‡è®ºæ–‡ä¸ä»…å¼€å¯äº†Transformer+å¤§æ•°æ®çš„æ–°èŒƒå¼ï¼Œ\n",
    "åŒæ—¶ä¹Ÿå¼€å¯äº†ã€ŠXXXX is all you needã€‹çš„çŒæ°´æ¨¡å¼ã€‚\n",
    "![Image Name](https://pic1.zhimg.com/80/v2-4b53b731a961ee467928619d14a5fd44_720w.jpg)\n",
    "\n",
    "Encoderç”±N=6ä¸ªç›¸åŒçš„layerç»„æˆï¼ŒlayeræŒ‡çš„å°±æ˜¯ä¸Šå›¾å·¦ä¾§çš„å•å…ƒï¼Œæœ€å·¦è¾¹æœ‰ä¸ªâ€œNxâ€ï¼Œè¿™é‡Œæ˜¯x6ä¸ªã€‚æ¯ä¸ªLayerç”±ä¸¤ä¸ªsub-layerç»„æˆï¼Œåˆ†åˆ«æ˜¯multi-head self-attention mechanismå’Œfully connected feed-forward networkã€‚å…¶ä¸­æ¯ä¸ªsub-layeréƒ½åŠ äº†residual connectionå’Œnormalisationã€‚\n",
    "\n",
    "#### 1.2.2.1 Multi-head self-attention\n",
    "å°±åœ¨ä¸Šé¢æˆ‘ä»¬åˆšåˆšç»™å¤§å®¶å±•ç¤ºè¿‡self-attentionçš„è¡¨ç¤ºå½¢å¼ï¼š\n",
    "![Image Name](https://cdn.kesci.com/upload/image/qvev8r8aca.png?imageView2/0/w/640/h/640)\n",
    "\n",
    "multi-head attentionåˆ™æ˜¯é€šè¿‡hä¸ªä¸åŒçš„çº¿æ€§å˜æ¢å¯¹Qï¼ŒKï¼ŒVè¿›è¡ŒæŠ•å½±ï¼Œæœ€åå°†ä¸åŒçš„attentionç»“æœæ‹¼æ¥èµ·æ¥ï¼š\n",
    "![Image Name](https://cdn.kesci.com/upload/image/qvev9v281a.png?imageView2/0/w/640/h/640)\n",
    "\n",
    "#### 1.2.2.2 Position-wise feed-forward networks\n",
    "è¿™å±‚ä¸»è¦æ˜¯æä¾›éçº¿æ€§å˜æ¢ã€‚Attentionè¾“å‡ºçš„ç»´åº¦æ˜¯\\[batch_size*feature_dim,num_head*head_size\\],ç¬¬äºŒä¸ªsub-layeræ˜¯ä¸ªå…¨è¿æ¥å±‚ï¼Œä¹‹æ‰€ä»¥æ˜¯position-wiseæ˜¯å› ä¸ºè¿‡çº¿æ€§å±‚æ—¶æ¯ä¸ªä½ç½®içš„å˜æ¢å‚æ•°æ˜¯ä¸€æ ·çš„ã€‚\n",
    "\n",
    "#### 1.2.2.3 Decoder\n",
    "Decoderå’ŒEncoderçš„ç»“æ„å·®ä¸å¤šï¼Œä½†æ˜¯å¤šäº†ä¸€ä¸ªattentionçš„sub-layerï¼Œè¿™é‡Œå…ˆæ˜ç¡®ä¸€ä¸‹decoderçš„è¾“å…¥è¾“å‡ºå’Œè§£ç è¿‡ç¨‹ï¼š\n",
    "\n",
    "è¾“å‡ºï¼šå¯¹åº”iä½ç½®çš„è¾“å‡ºè¯çš„æ¦‚ç‡åˆ†å¸ƒ\n",
    "è¾“å…¥ï¼šencoderçš„è¾“å‡º & å¯¹åº”i-1ä½ç½®decoderçš„è¾“å‡ºã€‚æ‰€ä»¥ä¸­é—´çš„attentionä¸æ˜¯self-attentionï¼Œå®ƒçš„Kï¼ŒVæ¥è‡ªencoderï¼ŒQæ¥è‡ªä¸Šä¸€ä½ç½®decoderçš„è¾“å‡º\n",
    "è§£ç ï¼šè¿™é‡Œè¦æ³¨æ„ä¸€ä¸‹ï¼Œè®­ç»ƒå’Œé¢„æµ‹æ˜¯ä¸ä¸€æ ·çš„ã€‚åœ¨è®­ç»ƒæ—¶ï¼Œè§£ç æ˜¯ä¸€æ¬¡å…¨éƒ¨decodeå‡ºæ¥ï¼Œç”¨ä¸Šä¸€æ­¥çš„ground truthæ¥é¢„æµ‹ï¼ˆmaskçŸ©é˜µä¹Ÿä¼šæ”¹åŠ¨ï¼Œè®©è§£ç æ—¶çœ‹ä¸åˆ°æœªæ¥çš„tokenï¼‰ï¼›è€Œé¢„æµ‹æ—¶ï¼Œå› ä¸ºæ²¡æœ‰ground truthäº†ï¼Œéœ€è¦ä¸€ä¸ªä¸ªé¢„æµ‹ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9D7C4188829410F9B67CEBAF6BA8DD2",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "60d980ca94c44a0017dc0c61",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 1.2.3ã€VIT Backbone\n",
    "ä¸ºäº†å°†transformerçš„ç»“æ„åº”ç”¨åˆ°è§†è§‰é¢†åŸŸä¸­æ¥ï¼ŒVITé‡‡å–äº†å°†å›¾ç‰‡åˆ‡å—çš„æ€æƒ³ï¼Œå¹¶å°†åˆ‡å—åçš„å›¾ç‰‡æ‹‰ç›´ï¼Œç„¶åæ˜ å°„æˆç±»ä¼¼word embeddingçš„è¯å‘é‡ã€‚\n",
    "åœ¨VIT ä¸­å­¦ä¹ å’Œæ²¿ç”¨äº†ç±»ä¼¼BERTçš„æ¡†æ¶,åœ¨æ•´ä¸ªæ¡†æ¶çš„ç¬¬ä¸€ä¸ªä½ç½®åŠ å…¥äº†ä¸€ä¸ªå¯å­¦ä¹ çš„cls-token é€šè¿‡æ•´ä¸ªencoder åå¾—åˆ°åˆ†ç±»ç”¨çš„ç‰¹å¾,ç„¶åé€šè¿‡ä¸€ä¸ªmlp çš„header å¾—åˆ°æœ€ç»ˆçš„åˆ†ç±»ç»“æœã€‚\n",
    "![Image Name](https://cdn.kesci.com/upload/image/qvevja4udf.png?imageView2/0/w/960/h/960)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "842175483C5A45D4886A5F18E90C90B7",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 2ã€ä»£ç è®²è§£\n",
    "è¿™éƒ¨åˆ†ä¸»è¦åˆ†æˆä¸¤ä¸ªéƒ¨åˆ†ï¼Œåˆ†åˆ«ä»‹ç»VITä¸­ä¸€äº›æ¯”è¾ƒå…³é”®çš„ä»£ç ï¼Œä»¥åŠç¬¬äºŒéƒ¨åˆ†ä¸­åŸºäºVITçš„ä»£ç æä¾›äº†ä¸€ä¸ªçŒ«ç‹—åˆ†ç±»çš„Demoã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00C07F383CE0476398273A0A634D27B3",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "60d980ca94c44a0017dc0c61",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 2.1ã€å…³é”®éƒ¨åˆ†è§£è¯»\n",
    "VITçš„ç»“æ„å…¶å®å°±æ˜¯å–äº†å®Œæ•´transformerç»“æ„çš„ä¸€åŠâ€”â€”encoderéƒ¨åˆ†æ¥è¿›è¡Œè§†è§‰ä¿¡æ¯çš„ç¼–ç ï¼Œæ‰€ä»¥VITä¸­éœ€è¦è®²è§£çš„å…³é”®éƒ¨åˆ†åŒ…æ‹¬ï¼Œå›¾åƒçš„åˆ†å—å’Œç¼–ç ï¼Œä½ç½®ç¼–ç ä»¥åŠåˆ†ç±»tokençš„ä½œç”¨è¿™ä¸‰ä¸ªéƒ¨åˆ†ã€‚\n",
    "### 2.1.1ã€å›¾åƒåˆ†å—åŠç¼–ç \n",
    "è¿™ä¸€éƒ¨åˆ†ä¸»è¦æ˜¯é€šè¿‡å°†å›¾åƒåˆ†ä¸º16*16çš„å—ï¼Œå¯¹äºæ¯ä¸ªå—å°†å®ƒç›¸åº”çš„æŠ½è±¡ä¸º768ç»´åº¦çš„word embeddingã€‚\n",
    "```\n",
    "class PatchEmbed(nn.Module):\n",
    "    \"\"\" Image to Patch Embedding\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768):\n",
    "        super().__init__()\n",
    "        img_size = to_2tuple(img_size)\n",
    "        patch_size = to_2tuple(patch_size)\n",
    "\t\t\t\t## æ ¹æ®å®é™…å›¾åƒçš„å¤§å°ï¼Œæ¥è®¡ç®—åˆ’åˆ†åpatchçš„æ•°é‡\n",
    "        num_patches = (img_size[1] // patch_size[1]) * (img_size[0] // patch_size[0])\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = num_patches\n",
    "\t\t\t\t## é€šè¿‡2Då·ç§¯æ¥å°†åˆ‡åˆ†åçš„patchå—æŠ½è±¡æˆå›ºå®šç»´åº¦çš„ç‰¹å¾è¡¨ç¤º\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        # FIXME look at relaxing size constraints\n",
    "        assert H == self.img_size[0] and W == self.img_size[1], \\\n",
    "            f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"\n",
    "        x = self.proj(x).flatten(2).transpose(1, 2)\n",
    "        return x\n",
    "```\n",
    "### 2.1.2ã€ä½ç½®ç¼–ç å’Œåˆ†ç±»token\n",
    "ä½ç½®ç¼–ç ä¸»è¦æ˜¯ç”¨æ¥è¡¨è¾¾å„ä¸ªè¯å‘é‡ä¹‹é—´çš„ç›¸å¯¹ä½ç½®å…³ç³»ï¼Œåœ¨transformeråŸæ–‡ä¸­æå‡ºä½¿ç”¨æ­£ä½™å¼¦çš„æ–¹å¼è¡¨è¾¾ï¼Œè€Œåœ¨VITä¸­ä½œè€…è¡¨ç¤ºå¯ä»¥ç›´æ¥è®¾ç½®å¯å­¦ä¹ çš„å‚æ•°å½¢å¼åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¿›è¡Œå­¦ä¹ ã€‚ç›¸å…³çš„ä»£ç è¡¨ç¤ºä¸€è¡Œå¯è§ã€‚\n",
    "```\n",
    "self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))\n",
    "```\n",
    "åˆ†ç±»tokenå°±æ˜¯æ¨¡ä»¿NLPï¼ŒåŠ å…¥äº†ä¸€ä¸ªé¢å¤–çš„è¯å‘é‡ï¼Œè¿™ä¸ªå‘é‡ä¼´éšç€ç½‘ç»œçš„è®­ç»ƒï¼Œå­¦ä¹ å…¨å±€ä¿¡æ¯çš„ç¼–ç ï¼Œå¹¶ä¸”åœ¨æœ€åè¢«é€å…¥åˆ†ç±»å±‚è¿›è¡Œåˆ†ç±»ä½¿ç”¨ã€‚ç›¸å…³çš„ä»£ç å’Œä½ç½®ç¼–ç éƒ¨åˆ†ç±»ä¼¼ï¼Œä¹Ÿæ˜¯é€šè¿‡ä¸€è¡Œä»£ç å°±å¯ä»¥è¡¨è¾¾ã€‚\n",
    "```\n",
    "self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0F22C63029194294833BFF0ECF189CE2",
    "jupyter": {},
    "mdEditEnable": true,
    "notebookId": "60d980ca94c44a0017dc0c61",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 2.2ã€å®Œæ•´Demoå®ç°\n",
    "åœ¨è¿™ä¸ªéƒ¨åˆ†ç»™å¤§å®¶ä¼™å„¿å±•ç¤ºä¸€ä¸ªåŸºäºVITçš„çŒ«ç‹—äºŒåˆ†ç±»ä»£ç æ¼”ç¤ºï¼Œè‡³äºä¸ºä»€ä¹ˆæ˜¯çŒ«ç‹—äºŒåˆ†ç±»ï¼Œæ˜¯å› ä¸ºç®€å•å•Šã€‚ä¸Šæ¬¡å†™çš„æ—¶å€™éšæ‰‹æ‰¾äº†ä¸ªçŒ«ç‹—çš„æ•°æ®é›†è·‘é€šäº†ã€‚æ—¢ç„¶è¿™ä¸ªæ•°æ®é›†å¯ä»¥ç®€æ´æ˜äº†çš„ç»™å¤§å®¶å±•ç¤ºæ€ä¹ˆå¿«é€Ÿæ­å»ºä¸€ä¸ªdemoï¼Œæˆ‘è®¤ä¸ºè¿™å°±è¶³å¤Ÿäº†ã€‚\n",
    "### 2.2.1ã€æ•°æ®å‡†å¤‡åŠå„ç§å„æ ·åŒ…çš„åŠ è½½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T16:54:39.053069Z",
     "start_time": "2022-01-15T16:54:39.034065Z"
    },
    "hide_input": false,
    "id": "D4D76440E82E43EE803FCA42844D4041",
    "jupyter": {},
    "notebookId": "60d980ca94c44a0017dc0c61",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# å„ç§åŒ…çš„åŠ è½½\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms, models, utils\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T16:41:56.524109Z",
     "start_time": "2022-01-15T16:41:56.200083Z"
    },
    "code_folding": [],
    "id": "27BAD6E6F0734D138F37809586600888",
    "jupyter": {},
    "notebookId": "60d980ca94c44a0017dc0c61",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] ç³»ç»Ÿæ‰¾ä¸åˆ°æŒ‡å®šçš„è·¯å¾„ã€‚: 'C:/Users/Harri/my_jupyter_notebook/data_cat-dog/train/'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_12200/4284818783.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[1;31m# !ls \"/home/mw/input/cat_dog1615/data/\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[0mtrain_dir\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"C:/Users/Harri/my_jupyter_notebook/data_cat-dog/train/\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 40\u001B[1;33m \u001B[0mtrain_ds\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mMyDataset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_dir\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     41\u001B[0m \u001B[0mtest_dir\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"C:/Users/Harri/my_jupyter_notebook/data_cat-dog/test/\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[0mtest_ds\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mMyDataset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_dir\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_12200/4284818783.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, data_path, train, transform)\u001B[0m\n\u001B[0;32m     13\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtransform\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 15\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath_list\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlistdir\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     16\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__getitem__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0midx\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] ç³»ç»Ÿæ‰¾ä¸åˆ°æŒ‡å®šçš„è·¯å¾„ã€‚: 'C:/Users/Harri/my_jupyter_notebook/data_cat-dog/train/'"
     ]
    }
   ],
   "source": [
    "# æ•°æ®çš„åŠ è½½å’Œåˆ‡åˆ†å·¥ä½œ\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_path: str, train=True, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.train_flag = train\n",
    "        if transform is None:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize(size=(224, 224)),  #å°ºå¯¸è§„èŒƒ\n",
    "                transforms.ToTensor(),  #è½¬åŒ–ä¸ºtensor\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transform\n",
    "        self.path_list = os.listdir(data_path)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        # img to tensor and label to tensor\n",
    "        img_path = self.path_list[idx]\n",
    "        if self.train_flag is True:\n",
    "            if img_path.split('.')[0] == 'dog':\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 0\n",
    "        else:\n",
    "            label = int(img_path.split('.')[0])  # split çš„æ˜¯strç±»å‹è¦è½¬æ¢ä¸ºint\n",
    "        label = torch.as_tensor(\n",
    "            label, dtype=torch.int64)  # å¿…é¡»ä½¿ç”¨long ç±»å‹æ•°æ®ï¼Œå¦åˆ™åé¢è®­ç»ƒä¼šæŠ¥é”™ expect long\n",
    "        img_path = os.path.join(self.data_path, img_path)\n",
    "        img = Image.open(img_path)\n",
    "        img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.path_list)\n",
    "\n",
    "\n",
    "# !ls \"/home/mw/input/cat_dog1615/data/\"\n",
    "train_dir = \"C:/Users/Harri/my_jupyter_notebook/data_cat-dog/train/\"\n",
    "train_ds = MyDataset(train_dir)\n",
    "test_dir = \"C:/Users/Harri/my_jupyter_notebook/data_cat-dog/test/\"\n",
    "test_ds = MyDataset(train_dir)\n",
    "full_ds = train_ds\n",
    "train_size = int(0.8 * len(full_ds))\n",
    "validate_size = len(full_ds) - train_size\n",
    "new_train_ds, validate_ds = torch.utils.data.random_split(\n",
    "    full_ds, [train_size, validate_size])\n",
    "# è°ƒç”¨torchçš„Dataloaderæ¥å¯¹æ•°æ®è¿›è¡Œå°è£…æˆå¯ä»¥ä½¿ç”¨çš„pipeline\n",
    "new_train_loader = torch.utils.data.DataLoader(new_train_ds,\n",
    "                                               batch_size=32,\n",
    "                                               shuffle=True,\n",
    "                                               pin_memory=True,\n",
    "                                               num_workers=0)\n",
    "validate_loader = torch.utils.data.DataLoader(validate_ds,\n",
    "                                              batch_size=32,\n",
    "                                              shuffle=True,\n",
    "                                              pin_memory=True,\n",
    "                                              num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40BBEB8E9626463F82CC59E6F232A941",
    "jupyter": {},
    "mdEditEnable": true,
    "notebookId": "60d980ca94c44a0017dc0c61",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 2.2.2ã€backboneçš„å…³é”®ä»£ç \n",
    "è¿™é‡Œå±•ç¤ºäº†ä¸€ä¸ªVITçš„backboneä»¥åŠå®ƒä¾èµ–çš„å„ç§å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T16:41:58.538791Z",
     "start_time": "2022-01-15T16:41:58.511788Z"
    },
    "id": "BCE1D1782B3F44EFBCE6CBFA3469D701",
    "jupyter": {},
    "notebookId": "60d980ca94c44a0017dc0c61",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# åˆ¤æ–­tæ˜¯ä¸æ˜¯ä¸€ä¸ªtupleå½¢å¼ï¼Œå¦‚æœä¸æ˜¯å°±æŠŠå®ƒå˜æˆtupleå½¢å¼ã€‚\n",
    "def pair(t):\n",
    "    return t if isinstance(t, tuple) else (t, t)\n",
    "\n",
    "\n",
    "### åœ¨resé“¾æ¥ä¹‹å‰çš„æ®‹å·®æ¨¡å—\n",
    "class PreNorm(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "\n",
    "###åŒ…å«äº†å…¨è¿æ¥å±‚ï¼ŒGeluä»¥åŠdropoutçš„å‰å‘ç½‘ç»œ\n",
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(dim, hidden_dim), nn.GELU(),\n",
    "                                 nn.Dropout(dropout),\n",
    "                                 nn.Linear(hidden_dim,\n",
    "                                           dim), nn.Dropout(dropout))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "###multi-head attentionæ¨¡å—\n",
    "class Attention(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, heads=8, dim_head=64, dropout=0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head * heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head**-0.5\n",
    "\n",
    "        self.attend = nn.Softmax(dim=-1)\n",
    "        ##åˆå§‹åŒ–qkvçš„ä¸ºå¯å­¦ä¹ çš„å…¨è”æ¥å±‚\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, n, _, h = *x.shape, self.heads\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=-1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=h), qkv)\n",
    "\n",
    "        dots = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n",
    "\n",
    "        attn = self.attend(dots)\n",
    "\n",
    "        out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "\n",
    "###å®Œæ•´çš„transformeræ¨¡å—\n",
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(\n",
    "                nn.ModuleList([\n",
    "                    PreNorm(\n",
    "                        dim,\n",
    "                        Attention(dim,\n",
    "                                  heads=heads,\n",
    "                                  dim_head=dim_head,\n",
    "                                  dropout=dropout)),\n",
    "                    PreNorm(dim, FeedForward(dim, mlp_dim, dropout=dropout))\n",
    "                ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "        return x\n",
    "\n",
    "\n",
    "class ViT(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 *,\n",
    "                 image_size,\n",
    "                 patch_size,\n",
    "                 num_classes,\n",
    "                 dim,\n",
    "                 depth,\n",
    "                 heads,\n",
    "                 mlp_dim,\n",
    "                 pool='cls',\n",
    "                 channels=3,\n",
    "                 dim_head=64,\n",
    "                 dropout=0.,\n",
    "                 emb_dropout=0.):\n",
    "        super().__init__()\n",
    "        image_height, image_width = pair(image_size)\n",
    "        patch_height, patch_width = pair(patch_size)\n",
    "        ##å¯¹æ¯”åŸå›¾æ˜¯ä¸æ˜¯å®Œæ•´å¯åˆ†\n",
    "        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "\n",
    "        num_patches = (image_height // patch_height) * (image_width //\n",
    "                                                        patch_width)\n",
    "        patch_dim = channels * patch_height * patch_width\n",
    "        assert pool in {\n",
    "            'cls', 'mean'\n",
    "        }, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
    "\n",
    "        ##å°†patch embeddingè½¬åŒ–ä¸ºå›ºå®šé•¿åº¦çš„è¯å‘é‡ç¼–ç \n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)',\n",
    "                      p1=patch_height,\n",
    "                      p2=patch_width),\n",
    "            nn.Linear(patch_dim, dim),\n",
    "        )\n",
    "        ##ä½ç½®ç¼–ç \n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
    "        ## åˆ†ç±»token\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim,\n",
    "                                       dropout)\n",
    "\n",
    "        self.pool = pool\n",
    "        self.to_latent = nn.Identity()\n",
    "\n",
    "        self.mlp_head = nn.Sequential(nn.LayerNorm(dim),\n",
    "                                      nn.Linear(dim, num_classes))\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = self.to_patch_embedding(img)\n",
    "        b, n, _ = x.shape\n",
    "\n",
    "        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b=b)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x += self.pos_embedding[:, :(n + 1)]\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        x = x.mean(dim=1) if self.pool == 'mean' else x[:, 0]\n",
    "\n",
    "        x = self.to_latent(x)\n",
    "        return self.mlp_head(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E476F3445FDE44A4BF4B16096E28F993",
    "jupyter": {},
    "mdEditEnable": true,
    "notebookId": "60d980ca94c44a0017dc0c61",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 2.2.3ã€è®­ç»ƒè¿‡ç¨‹\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T16:42:00.261720Z",
     "start_time": "2022-01-15T16:42:00.249721Z"
    },
    "id": "9DDA149E6948416285DC47637DD202BB",
    "jupyter": {},
    "notebookId": "60d980ca94c44a0017dc0c61",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#å®šä¹‰ä¸€äº›å·¥å…·ç±»\n",
    "class AvgrageMeter(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.cnt = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.sum += val * n\n",
    "        self.cnt += n\n",
    "        self.avg = self.sum / self.cnt\n",
    "\n",
    "\n",
    "def accuracy(output, label, topk=(1, )):\n",
    "    maxk = max(topk)\n",
    "    batch_size = label.size(0)\n",
    "\n",
    "    # è·å–å‰Kçš„ç´¢å¼•\n",
    "    _, pred = output.topk(maxk, 1, True, True)  #ä½¿ç”¨topkæ¥è·å¾—å‰kä¸ªçš„ç´¢å¼•\n",
    "    pred = pred.t()  # è¿›è¡Œè½¬ç½®\n",
    "    # eqæŒ‰ç…§å¯¹åº”å…ƒç´ è¿›è¡Œæ¯”è¾ƒ view(1,-1) è‡ªåŠ¨è½¬æ¢åˆ°è¡Œä¸º1,çš„å½¢çŠ¶ï¼Œ expand_as(pred) æ‰©å±•åˆ°predçš„shape\n",
    "    # expand_as æ‰§è¡ŒæŒ‰è¡Œå¤åˆ¶æ¥æ‰©å±•ï¼Œè¦ä¿è¯åˆ—ç›¸ç­‰\n",
    "    correct = pred.eq(label.view(\n",
    "        1, -1).expand_as(pred))  # ä¸æ­£ç¡®æ ‡ç­¾åºåˆ—å½¢æˆçš„çŸ©é˜µç›¸æ¯”ï¼Œç”ŸæˆTrue/FalseçŸ©é˜µ\n",
    "    #     print(correct)\n",
    "\n",
    "    rtn = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].contiguous().view(-1).float().sum(\n",
    "            0)  # å‰kè¡Œçš„æ•°æ® ç„¶åå¹³æ•´åˆ°1ç»´åº¦ï¼Œæ¥è®¡ç®—trueçš„æ€»ä¸ªæ•°\n",
    "        rtn.append(correct_k.mul_(\n",
    "            100.0 / batch_size))  # mul_() ternsor çš„ä¹˜æ³•  æ­£ç¡®çš„æ•°ç›®/æ€»çš„æ•°ç›® ä¹˜ä»¥100 å˜æˆç™¾åˆ†æ¯”\n",
    "    return rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T16:42:26.295912Z",
     "start_time": "2022-01-15T16:42:25.526205Z"
    },
    "id": "7D91BD234074460C8E5FA5C76B9B10D2",
    "jupyter": {},
    "notebookId": "60d980ca94c44a0017dc0c61",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4131aacc368463fb3f08b6c470809e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# ç½‘ç»œçš„è®­ç»ƒä»£ç \n",
    "def train(epoch, train_loader, device, model, criterion, optimizer):\n",
    "    model = model.to(device)\n",
    "    for e in range(epoch):\n",
    "        model.train()\n",
    "        top1 = AvgrageMeter()\n",
    "        train_loss = 0.0\n",
    "        train_loader = tqdm(train_loader)\n",
    "        train_loader.set_description('[%s%04d/%04d %s%f]' %\n",
    "                                     ('Epoch:', e + 1, epoch, 'lr:', 0.001))\n",
    "        for i, data in enumerate(train_loader, 0):  # 0æ˜¯ä¸‹æ ‡èµ·å§‹ä½ç½®é»˜è®¤ä¸º0\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            # åˆå§‹ä¸º0ï¼Œæ¸…é™¤ä¸Šä¸ªbatchçš„æ¢¯åº¦ä¿¡æ¯\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # topk å‡†ç¡®ç‡è®¡ç®—\n",
    "            prec1, prec2 = accuracy(outputs, labels, topk=(1, 2))\n",
    "            n = inputs.size(0)\n",
    "            top1.update(prec1.item(), n)\n",
    "            train_loss += loss.item()\n",
    "            postfix = {\n",
    "                'train_loss': '%.6f' % (train_loss / (i + 1)),\n",
    "                'train_acc': '%.6f' % top1.avg\n",
    "            }\n",
    "            train_loader.set_postfix(log=postfix)\n",
    "            ######ä¸æƒ³ç­‰ä»–è®­ç»ƒå®Œï¼Œæ‰€ä»¥æˆ‘breakäº†ï¼Œå®é™…ä½¿ç”¨è¯·æ³¨é‡Šæ‰\n",
    "            break\n",
    "    print('Finished Training')\n",
    "\n",
    "\n",
    "net = ViT(image_size=224,\n",
    "          patch_size=32,\n",
    "          num_classes=2,\n",
    "          dim=1024,\n",
    "          depth=6,\n",
    "          heads=16,\n",
    "          mlp_dim=2048,\n",
    "          dropout=0.1,\n",
    "          emb_dropout=0.1)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "train(1, new_train_loader, device, net, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FD04F8B564AD42FBA992D4EF999E2701",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 3ã€Ending\n",
    "## 3.1ã€æ€»ç»“åŠå±•æœ›\n",
    "ViTï¼ˆvision transformerï¼‰æ˜¯Googleåœ¨2020å¹´æå‡ºçš„ç›´æ¥å°†transformeråº”ç”¨åœ¨å›¾åƒåˆ†ç±»çš„æ¨¡å‹ï¼Œåé¢å¾ˆå¤šçš„å·¥ä½œéƒ½æ˜¯åŸºäºViTè¿›è¡Œæ”¹è¿›çš„ã€‚\n",
    "ViTç®—æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„å¼€å§‹ï¼Œè™½ç„¶ä¹Ÿå­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œä½†æ˜¯è‡³å°‘è¯æ˜äº†çº¯ç²¹çš„transformeråœ¨CVé¢†åŸŸåº”ç”¨çš„å¯èƒ½æ€§ã€‚\n",
    "VITä¸­ä¸€ä¸ªæ¯”è¾ƒä¸¥é‡çš„é—®é¢˜å°±æ˜¯éœ€è¦è¶…å¤§çš„æ•°æ®é›†å»è¿›è¡Œé¢„è®­ç»ƒ\n",
    "è¿™æœ€èµ·ç è¯æ˜äº†ä¸€ä¸ªé—®é¢˜ï¼ŒMoney is all you needï¼\n",
    "## 3.2ã€ç¢ç¢å¿µçš„ç»“æŸè¯­\n",
    "å„ä½è¯»è€…è€çˆ·å¤§å®¶å¥½ï¼Œæœ¬æœŸå†…å®¹åˆ°è¿™é‡Œå°±ç»“æŸå•¦ï¼\n",
    "è¿™é‡Œä¸ºäº†ç®€å•ï¼ˆå·æ‡’ï¼‰ä»…ä»…æ˜¯è®­ç»ƒäº†ä¸€ä¸ªepochä¿è¯ä»£ç çš„é€šç”¨æ€§ã€‚ï¼ˆè½»å–·ï¼‰\n",
    "è¿™æ˜¯Transformerå°è¯•ç‰›åˆ€ç³»åˆ—ç¬¬ä¸€ç¯‡ï¼Œæ¬¢è¿å¤§å®¶æ¥å’Œé²¸å¹³å°ä¸€èµ·å‚ä¸è®¨è®ºå•¦ï¼\n",
    "ç›¸å…³çš„ä»£ç å‡å¯å¼€æºè‡ªç”¨ï¼Œå•†ä¸šç”¨é€”é™¤å¤–ï¼Œå„ä½è¯»è€…è€çˆ·è¯·è‡ªå–ã€‚\n",
    "ç›®å‰ä»£ç æ”¯æŒcpuå’Œgpuä¸‹è®­ç»ƒã€‚\n",
    "æŒ¥æ‰‹ğŸ™‹â€â™‚ï¸ï¼Œæˆ‘ä»¬ä¸‹æ¬¡å†è§"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "æ— ",
  "gist": {
   "data": {
    "description": "my_jupyter_notebook/VIT demo.ipynb",
    "public": true
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "516px",
    "width": "425px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "389.153px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}